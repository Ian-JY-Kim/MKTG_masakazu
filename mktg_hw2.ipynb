{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 23:00:49,163\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "import random\n",
    "import math\n",
    "import time \n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "import ray\n",
    "ray.init(num_cpus= 10, ignore_reinit_error=True)\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define true parameters \n",
    "alpha_1 = 1\n",
    "alpha_2 = 1\n",
    "beta_loc = -0.1\n",
    "beta_scale = 1\n",
    "price_loc = 2\n",
    "price_scale = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A. Simulate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DGP():\n",
    "    # create frame of the dataset \n",
    "    # i X t dataframe shape: (1000 X 2)\n",
    "    i_list = np.full(20, 1)\n",
    "    t_list = np.array([t for t in range(1, 21)])\n",
    "    for i in range(2,101):\n",
    "        i_list = np.concatenate((i_list, np.full(20, i)), axis = None)\n",
    "        t_list = np.concatenate((t_list, np.array([t for t in range(1, 21)])), axis = None)\n",
    "    df_simulation = df({'i': i_list, 't': t_list})\n",
    "\n",
    "    # t p_1t p_2t dataframe (10 X 2)\n",
    "    # price is varying across time \n",
    "    t_list_20 = np.array([t for t in range(1, 21)])\n",
    "    p_1_draw = np.random.normal(price_loc, price_scale, 20)\n",
    "    p_2_draw = np.random.normal(price_loc, price_scale, 20)\n",
    "    df_price = df({'t': t_list_20, 'p_1t': p_1_draw, 'p_2t': p_2_draw})\n",
    "\n",
    "    \n",
    "    # draw beta for each i \n",
    "    # and merge it to the df_simulation\n",
    "    i_list_100 = np.array([i for i in range(1, 101)])\n",
    "    beta_draw = np.random.normal(beta_loc, beta_scale, 100)\n",
    "    df_beta = df({\"i\": i_list_100, \"beta\": beta_draw})\n",
    "\n",
    "    # merge\n",
    "    df_simulation = pd.merge(df_simulation, df_price, left_on=\"t\", right_on=\"t\")\n",
    "    df_simulation = pd.merge(df_simulation, df_beta, left_on=\"i\", right_on=\"i\")\n",
    "    df_simulation = df_simulation.sort_values(by = ['i', 't'], ascending= True)\n",
    "\n",
    "    # simulate decision\n",
    "    p_1_array = np.array(df_simulation['p_1t'])\n",
    "    p_2_array = np.array(df_simulation['p_2t'])\n",
    "    beta_array = np.array(df_simulation['beta'])\n",
    "    exp_1_array = np.exp(alpha_1 + beta_array*p_1_array)\n",
    "    exp_2_array = np.exp(alpha_2 + beta_array*p_2_array)\n",
    "    prob_1_array = exp_1_array/(1 + exp_1_array + exp_2_array)\n",
    "    prob_2_array = exp_2_array/(1 + exp_1_array + exp_2_array)\n",
    "    prob_0_array = 1 - prob_1_array - prob_2_array\n",
    "    u_array = np.random.uniform(0,1,2000)\n",
    "\n",
    "    # let the error term (epsilon) determine the decision\n",
    "    # outside option <-- left extreme\n",
    "    d_0t_bool = (u_array < prob_0_array).astype(int)\n",
    "    # decision for product 1 <-- middle part\n",
    "    d_1t_temp1 = (u_array >= prob_0_array)\n",
    "    d_1t_temp2 = (u_array < prob_0_array + prob_1_array)\n",
    "    d_1t_bool = (d_1t_temp1 * d_1t_temp2).astype(int)\n",
    "    # decision for product 2 <-- right extreme\n",
    "    d_2t_bool = (u_array >= prob_0_array + prob_1_array).astype(int)\n",
    "\n",
    "    df_simulation['d_0t'] = d_0t_bool\n",
    "    df_simulation['d_1t'] = d_1t_bool\n",
    "    df_simulation['d_2t'] = d_2t_bool\n",
    "\n",
    "    return df_simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sample = DGP()\n",
    "#data_sample.to_csv(\"data_sample.csv\")\n",
    "data_sample= pd.read_csv(\"data_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B. Simulated MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def multiplyAll(s):\n",
    "    ans = 1\n",
    "    for n in s:\n",
    "        ans *= n\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLE(theta, data_sample):\n",
    "    alpha_1, alpha_2, beta_loc, beta_scale = theta\n",
    "    \n",
    "    # parallelize for loop on individual i\n",
    "    @ray.remote\n",
    "    def i_prob(i):\n",
    "        work_data = data_sample.loc[data_sample['i']==i]\n",
    "        np.random.seed(i)\n",
    "        beta_draw = np.random.uniform(-2,2,300) # number of draw matters for the MLE estimates\n",
    "                                                # higher number of beta draw will make the integration precise\n",
    "                                                # Question: How do we set up lower and upper limit of beta? \n",
    "\n",
    "        # within each i, calculate the likelihood\n",
    "        def prob_calculate(beta):\n",
    "            exp_1_array = np.exp(alpha_1 + beta*work_data['p_1t'].values)\n",
    "            exp_2_array = np.exp(alpha_2 + beta*work_data['p_2t'].values)\n",
    "            prob_1_array = exp_1_array/(1 + exp_1_array + exp_2_array)\n",
    "            prob_2_array = exp_2_array/(1 + exp_1_array + exp_2_array)\n",
    "            prob_0_array = 1 - prob_1_array - prob_2_array\n",
    "            prob_array = prob_0_array*work_data['d_0t'].values + prob_1_array*work_data['d_1t'].values + prob_2_array*work_data['d_2t'].values\n",
    "            conditional_prob = multiplyAll(prob_array) # probability condiotinal on beta\n",
    "            prob = conditional_prob * norm.pdf(beta, beta_loc, beta_scale) # unconditional probability\n",
    "            return prob\n",
    "\n",
    "        vec_prob_calculate = np.vectorize(prob_calculate)\n",
    "        # take average of the probability for 300 many drawn beta\n",
    "        mc_prob = vec_prob_calculate(beta_draw).mean()\n",
    "        # return the log likelihood\n",
    "        return -np.log(mc_prob)\n",
    "\n",
    "    likelihood_list = [i_prob.remote(i) for i in range(1,101)]\n",
    "    likelihood_array = np.array(ray.get(likelihood_list))\n",
    "\n",
    "    return likelihood_array.sum()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.09464869,  1.05299484, -0.07894199,  0.85991289])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLE_result = minimize(MLE, [0.5, 0.5, 0, 0.5], args = (data_sample), method='L-BFGS-B', options={'maxiter':200})\n",
    "MLE_result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C. Hierarchical Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here I assume that a researcher aleready knows $\\alpha_1$ and $\\alpha_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def personal_llh(beta_candidate, personal_data):\n",
    "\n",
    "    p_1_array = np.array(personal_data['p_1t'])\n",
    "    p_2_array = np.array(personal_data['p_2t'])\n",
    "    d_0t_array = np.array(personal_data['d_0t'])\n",
    "    d_1t_array = np.array(personal_data['d_1t'])\n",
    "    d_2t_array = np.array(personal_data['d_2t'])\n",
    "    \n",
    "    exp_1_array = np.exp(alpha_1 + beta_candidate*p_1_array)\n",
    "    exp_2_array = np.exp(alpha_2 + beta_candidate*p_2_array)\n",
    "    prob_1_array = exp_1_array/(1 + exp_1_array + exp_2_array)\n",
    "    prob_2_array = exp_2_array/(1 + exp_1_array + exp_2_array)\n",
    "    prob_0_array = 1 - prob_1_array - prob_2_array\n",
    "\n",
    "    prob_array = d_0t_array * np.log(prob_0_array) + d_1t_array * np.log(prob_1_array) + d_2t_array * np.log(prob_2_array)\n",
    "    log_sum = prob_array.sum()\n",
    "\n",
    "    return log_sum    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_gamma_draw(s_bar):\n",
    "    nu_1 = 101 \n",
    "    s_1 = (1 + 100*s_bar)/101\n",
    "\n",
    "    eta_draw = np.random.normal(0,1,nu_1)\n",
    "    eta_temp = (eta_draw/np.sqrt(s_1))**2\n",
    "    r = eta_temp.mean()\n",
    "\n",
    "    return 1/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_dump = []\n",
    "mu_dump = []\n",
    "sigma_dump = []\n",
    "\n",
    "mu_pre = 0\n",
    "sigma_pre = 0.5\n",
    "beta_pre = np.zeros(100)\n",
    "\n",
    "for t in range(2000):\n",
    "    #1. update beta\n",
    "    beta_post = []\n",
    "    for i in range(1,101):\n",
    "        # draw new beta\n",
    "        personal_data = data_sample.loc[data_sample['i']==i]\n",
    "        personal_beta_candidate = np.random.normal(mu_pre, sigma_pre, 1)[0]\n",
    "        personal_beta_pre = beta_pre[i-1]\n",
    "\n",
    "        # decide accept/reject\n",
    "        criteria_mu = np.random.uniform(0,1,1)\n",
    "        llh_pre = personal_llh(personal_beta_pre, personal_data)\n",
    "        llh_candidate = personal_llh(personal_beta_candidate, personal_data)\n",
    "\n",
    "        # update \n",
    "        if math.log(criteria_mu) <= llh_candidate - llh_pre:\n",
    "            beta_post.append(personal_beta_candidate)\n",
    "        else:\n",
    "            beta_post.append(personal_beta_pre)\n",
    "    \n",
    "    beta_dump.append(np.array(beta_post))\n",
    "\n",
    "    #2. update mu\n",
    "    mu_loc = np.array(beta_post).mean()\n",
    "    mu_scale = sigma_pre/10\n",
    "    mu_post = np.random.normal(mu_loc, mu_scale, 1)[0]\n",
    "    mu_dump.append(mu_post)\n",
    "\n",
    "    #3. update sigma\n",
    "    #calculate s_bar\n",
    "    beta_bar = np.array(beta_post).mean()\n",
    "    error_array = np.array(beta_post) - beta_bar\n",
    "    sum_sq_error = error_array**2\n",
    "    s_bar = sum_sq_error.mean()\n",
    "    sigma_post = inverted_gamma_draw(s_bar)\n",
    "    sigma_dump.append(sigma_post)\n",
    "\n",
    "    #4. iterate\n",
    "    beta_pre = beta_post\n",
    "    mu_pre = mu_post\n",
    "    sigma_pre = sigma_post\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian estimates for beta_loc:  -0.46974504683347146\n",
      "Bayesian estimates for beta_scale:  0.06287205266837353\n"
     ]
    }
   ],
   "source": [
    "print(\"Bayesian estimates for beta_loc: \", np.array(beta_dump[500:2000]).mean())\n",
    "print(\"Bayesian estimates for beta_scale: \", np.array(sigma_dump[500:2000]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian estimates for beta_loc:  -0.4706515373711152\n",
      "Bayesian estimates for beta_scale:  0.06613425922290624\n"
     ]
    }
   ],
   "source": [
    "print(\"Bayesian estimates for beta_loc: \", np.array(beta_dump[:]).mean())\n",
    "print(\"Bayesian estimates for beta_scale: \", np.array(sigma_dump[:]).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4058ae7d101d4d34f9fe782bbb6316095f0ede2a1a2e6a1564fc2428590ee83d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
